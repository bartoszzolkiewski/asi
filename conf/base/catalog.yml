# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html


## RAW ##
application_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/application_data.csv

columns_description:
  type: pandas.CSVDataSet
  filepath: data/01_raw/columns_description.csv

previous_application:
  type: pandas.CSVDataSet
  filepath: data/01_raw/previous_application.csv

## INTERMEDIATE ##
previous_application_dropped:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/previous_application_dropped.pq

application_data_dropped:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/application_data_dropped.pq

merged_df:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/merged_df.pq

## PRIMARY ##
merged_df_fixed:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/merged_df_fixed.pq

## FEATURE ##
feature_dataframe:
  type: pandas.ParquetDataSet
  filepath: data/04_feature/feature_dataframe.pq

## MODEL INPUT ##
model_input:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/model_input.pq

model_input_scaled:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/model_input_scaled.pq

## MODELS ##
decision_tree:
  type: pickle.PickleDataSet
  filepath: data/06_models/decision_tree.pickle
  versioned: true