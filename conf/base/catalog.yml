# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html


## RAW ##
application_data:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: pandas.CSVDataSet  # or any valid kedro DataSet
      filepath: data/01_raw/application_data.csv # must be a local file, wherever you want to log the data in the end

columns_description:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: pandas.CSVDataSet  
      filepath: data/01_raw/columns_description.csv

previous_application:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: pandas.CSVDataSet 
      filepath: data/01_raw/previous_application.csv

## INTERMEDIATE ##
previous_application_dropped:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/previous_application_dropped.pq

application_data_dropped:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/application_data_dropped.pq

merged_df:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/merged_df.pq

## PRIMARY ##
merged_df_fixed:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/merged_df_fixed.pq

## FEATURE ##
feature_dataframe:
  type: pandas.ParquetDataSet
  filepath: data/04_feature/feature_dataframe.pq

## MODEL INPUT ##
model_input:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/model_input.pq

model_input_scaled:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/model_input_scaled.pq

## MODELS ##

decision_tree:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/decision_tree.pkl
  
decision_forest:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/decision_forest.pkl
